{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 한글 문서의 분류\n",
    "네이버 뉴스 데이터를 크롤링하여 분류 연습<br>\n",
    "기사 내용과 기사를 쓴 뉴스 회사의 이름을 학습하여 기사가 어느 뉴스회사의 기사인지 예측하고자 함\n",
    "### data file 내용\n",
    "'국민일보', '전자신문', '한겨레', TV조선' 등 네이버 뉴스 크롤링을 하여 총 3865개의 기사를 수집\n",
    "csv 파일 안에 뉴스 회사 이름, 기사내용 의 순으로 저장되어 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "text = []\n",
    "y = []\n",
    "with open('navernews_utf2.csv', encoding='utf-8') as csvfile:\n",
    "    csvreader = csv.reader(csvfile)\n",
    "    for row in csvreader:\n",
    "        #print(row)\n",
    "        if row: #그 줄에 내용이 있는 경우에만\n",
    "            text.append(row[1]) #기사를 text 리스트에 추가\n",
    "            y.append(row[0]) #뉴스 회사이름을 text 리스트에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of samples: 3865\n",
      "뉴스 이름: {'국민일보', '전자신문', '한겨레', 'TV조선', '서울경제', '파이낸셜뉴스', '머니투데이', '매일신문', '한국경제', '조선일보', '아이뉴스24', '노컷뉴스', '세계일보', '동아일보', 'press', '이데일리', '데일리안', '아시아경제', '스포츠서울', '경향신문', '뉴스1', '디지털타임스', '뉴시스', '헤럴드경제', '한국일보', '연합뉴스'}\n"
     ]
    }
   ],
   "source": [
    "print('Num of samples: {}'.format(len(text)))\n",
    "print('뉴스 이름: {}'.format(set(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data and labels into a training and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(text, y, random_state=0)\n",
    "# 비율을 지정하지 않으면 75:25로 분할됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2898"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train) #3865의 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt #konlpy에서 Twitter 형태소 분석기를 import\n",
    "#from konlpy.tag import Twitter #konlpy에서 Twitter 형태소 분석기를 import\n",
    "twitter_tag = Okt()\n",
    "#twitter_tag = Twitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['전국', '장애인', '부모', '연대', '회원', '들', '이', '2일', '오전', '발달장애', '주간', '활동', '서비스', '도입', '을', '촉구', '하며', '청와대', '춘추관', '진입', '을', '시도', '하다', '실패한', '후', '문재인', '대통령', '면담', '요청서', '를', '청와대', '관계자', '에게', '전달', '하고', '있다', '.', '청와대', '사진기', '자단', '▶', '네이버', '메인', '에서', '받아', '보기', '▶', '두고', '두고', '읽는', '뉴스', '▶', '인기', '무료', '만화', '©', '(www.khan.co.kr', '),', '무단', '전', '재', '및', '재', '배포', '금지']\n"
     ]
    }
   ],
   "source": [
    "print(twitter_tag.morphs(X_train[1])) #둘째 기사에 대해 형태소 단위로 tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['전국',\n",
       " '장애인',\n",
       " '부모',\n",
       " '연대',\n",
       " '회원',\n",
       " '오전',\n",
       " '발달장애',\n",
       " '주간',\n",
       " '활동',\n",
       " '서비스',\n",
       " '도입',\n",
       " '촉구',\n",
       " '청와대',\n",
       " '춘추관',\n",
       " '진입',\n",
       " '시도',\n",
       " '후',\n",
       " '문재인',\n",
       " '대통령',\n",
       " '면담',\n",
       " '요청서',\n",
       " '청와대',\n",
       " '관계자',\n",
       " '전달',\n",
       " '청와대',\n",
       " '사진기',\n",
       " '자단',\n",
       " '네이버',\n",
       " '메인',\n",
       " '보기',\n",
       " '뉴스',\n",
       " '인기',\n",
       " '무료',\n",
       " '만화',\n",
       " '무단',\n",
       " '재',\n",
       " '및',\n",
       " '재',\n",
       " '배포',\n",
       " '금지']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_tag.nouns(X_train[1]) #둘째 기사에서 명사만 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twit_tokenizer(text): # Twitter 형태소 분석기의 명사추출함수를 tokenizer 함수로 사용\n",
    "    return twitter_tag.nouns(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score 0.943064182194617\n",
      "Test score 0.8748707342295761\n",
      "(2898, 8555)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#tfidf = TfidfVectorizer(tokenizer=twit_tokenizer, min_df=3, max_df=0.90, max_features=1000, use_idf=True, sublinear_tf=True)\n",
    "tfidf = TfidfVectorizer(tokenizer=twit_tokenizer, min_df=2) #Twitter 형태소분석기에서 명사만 추출하는 함수를 tokenizer로 이용\n",
    "# twit_tokenizer 대신 twitter_tag.nouns를 직접 써도 됨\n",
    "# 하나의 문서에서만 출현한 단어는 쓸모가 없으므로 제외, 즉 최소 document frequency를 2로 설정\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train) # train data 변환 -> tfidf vector\n",
    "X_test_tfidf = tfidf.transform(X_test) # test data 변환 -> tfidf vector\n",
    "\n",
    "clf = LogisticRegression() # logistic regression 분류기 선언\n",
    "clf.fit(X_train_tfidf, y_train) # 분류기 학습\n",
    "print('Train score', clf.score(X_train_tfidf, y_train)) # train data 예측정확도\n",
    "print('Test score', clf.score(X_test_tfidf, y_test)) # test data 예측정확도\n",
    "print(X_train_tfidf.shape) # 총 8555개의 명사로 이루어짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(서울=) 문무일 검찰총장이 검·경 수사권 조정 법안 등의 패스트트랙(신속처리안건) 지정을 비판해 파문을 일으켰다. 해외 순방 중인 문 총장은 지난 1일 대검을 통해 낸 입장자료에서 \"신속처리안건으로 지정된 법안들은 견제와 균형이라는 민주주의 원리에 반한다\"며 \"검찰총장으로서 우려를 금할 수 없다\"고 밝혔다. 문 총장이 권력기관 개혁 법안의 패스트트랙 지정에 검찰 수장으로서 우려의 목소리를 낸 것은 검찰 조직에서는 환영받을지 모르겠다. 그러나 국민의 눈에는 대의기관인 국회의 결정에 뒤늦게 제동을 하는 듯한 모습으로 비쳐 부적절해 보인다. 문 총장이 임기를 두달여 남긴 시점에 반기를 드는 듯한 행보를 보이는 것은 이해하기 어렵다. 정의당 이정미 대표는 2일 문 총장을 겨냥해 \"국회의 정당한 입법절차에 정부 관료가 공공연히 반기 드는 것이야말로 민주주의 원리를 망각한 행동\"이라며 \"문 총장의 언행은 기득권을 포기하지 못하는 검찰 권력의 현실을 그대로 보여준다\"고 직격탄을 날렸다.권력기관 개혁은 검찰이 자초한 측면이 크다. 형사사건 수사, 수사지휘, 기소권을 모두 갖는 소추(訴追) 기관인 검찰은 그동안 국민 편에 서기보다는 권력 편에서 막강한 권한을 휘두르며 국민 위에 군림해왔다. 김학의 전 법무부 차관의 \\'별장 성폭행\\' 사건이 불거졌을 때 납득하기 어려운 사유로 끝내 무혐의 처분한 조직이 바로 검찰이다. \\'권력의 시녀\\'라는 말이 그냥 나온 게 아니다. 검찰은 본연의 업무라 할 수 있는 경찰 형사사건 수사지휘보다 공안, 특수, 강력, 금융 등으로 직접수사 범위를 확대해가며 기득권 유지와 강화에 매달려왔다. 국민의 검찰개혁 요구는 검찰의 자업자득인 셈이다.그렇지만 검·경 수사권 조정법과 공수처 설치법 등 권력기관 개혁법안은 보완할 필요는 있다는 전문가 견해가 적지 않다. 여당인 더불어민주당의 조응천 의원은 패스트트랙으로 지정된 수사권조정법안이 그대로 통과될 경우 국내 정보업무를 전담하는 경찰이 통제를 거의 안 받고 1차 수사권을 행사함으로써 \\'경찰국가화\\'할 수 있다고 지적했다. 같은 당 금태섭 의원은 일정 직급 이상의 공직자를 수사하는 공수처가 국제 기준에 맞지 않고 권력자가 악용할 수 있다는 점 등을 들어 아예 \\'공수처 반대\\'를 외치고 있다. 두 의원이 모두 검사 출신이지만, 이들의 우려와 지적에도 귀담아들어야 할 대목은 있다.       패스트트랙으로 지정된 권력기관 개혁법안은 최장 300일 넘게 국회에서 논의할 수 있다. 이 기간에 여야가 머리를 맞대고 각계 의견을 수렴해 시대에 맞는 최적의 법을 만들기 바란다. 검·경 수사권 조정만 해도 벌써 경찰 권력의 비대화를 우려하는 목소리가 있다. 공수처 신설에는 헌법상 평등의 원칙에 위배된다는 지적이 따른다. 권력기관 개혁은 검찰 수사권을 제한하되 경찰과 공수처를 견제할 수단과 장치도 반드시 마련되는 방향으로 이뤄져야 한다. 경찰과 공수처가 무소불위의 새로운 권력기관이 되는 것은 막아야 한다는 뜻이다.▶네이버 홈에서 [] 채널 구독하기▶뭐 하고 놀까? #흥  ▶쇼미더뉴스! 오늘 많이 본 뉴스영상',\n",
       " '\"한미 정상, 인도적 차원 식량제공 공감대\"\"아직 확정된 것은 없지만, 검토 들어갈 것\"\"국제기구 보고서, 北 어린이 상황 도와야한다\"美 FFVD에는 \"협상 재개 방안이 포괄적으로 들어간 것\"[CBS 황영찬 기자]청와대 자료사진. (사진=황진환 기자)청와대는 한미정상이 북한에 대한 인도적 차원의 식량지원에 공감대를 형성했다는 판단 하에 제공 방법·시기 등을 본격적으로 검토할 방침이다.청와대 관계자는 8일 기자들과 만나 \"전날 통화한 한미 정상은 인도적 차원의 식량제공에 대한 지지의사를 밝히셨다\"며 \"(대북 식량지원과 관련한) 모든 사안에 대해 이제 검토에 들어가야 하는 단계\"라고 밝혔다.이 관계자는 \"어떤 종류의 품목이, 어떤 방법으로, 어느정도 제공될 지 궁금증이 많으실텐데, 이제 논의 과정에 들어가는 것이므로 확정된 것은 없다\"고 설명했다. 청와대는 국제적 기구를 통한 지원이나 직접 지원 등을 포함한 모든 가능성을 열어놓고 논의 과정을 진행할 예정이다.한미 정상간의 통화에서는 식량 규모나 형식에 대한 구체적인 이야기는 오가지 않았다고 한다.또 이 관계자는 북한의 식량 상황에 대해 \"최근 세계식량계획(WFP)과 유엔식량농업기구(FAO)가 등에서 실태파악 보고서를 밝혔다\"며 \"해당 보고서에는 현재 어린이와 그 가족들이 어려운 시기를 견딜 수 있도록 도와야 한다는 말이 있는데, 정부도 그 정도로 파악하고 있다\"고 전했다.백악관 발표에는 \\'최종적이고 완전히 검증된 북한 비핵화(FFVD)\\'만 적시됐고, 식량지원에 대한 언급이 빠졌다는 지적에 대해서는 \"미국 쪽에서 어느 수준까지 발표할지는 알 수 없지만 있는 내용을 그대로 전달한 것\"이라며 \"FFVD에는 북한이 비핵화를 위한 궤도에서 이탈하지 않도록 하면서 조기에 비핵화 협상을 재개하는 방안이 포괄적으로 들어있다는 생각\"이라고 강조했다.이 관계자는 \"전날 두 정상은 북한의 발사체 발사 이후, 트럼프 대통령의 트위터나 폼페이오 국무장관의 발언 등이 북한을 둘러싼 상황을 관리하는데 효과적이었다는데 평가를 같이 했다\"고 말하기도 했다.한편, 이 관계자는 트럼프 대통령의 방한 시점에 대해서는 \"관례적으로 정상 간의 만남은 구체적 일정이 완전히 확정되기 전에는 발표할 수 없다\"며 \"두 정상은 방한에 대해 긴밀히 협의해 나가기로 했다\"고만 말했다.▶ 확 달라진 ▶  구독 서비스▶ 재미와 흥미가 있는 동영상 구경하기 techan92@cbs.co.kr저작권자 © CBS  무단전재 및 재배포 금지',\n",
       " '(서울=) 한상균 기자 = 발달장애 주간활동 서비스도입을 촉구하는 전국장애인부모연대 회원들이 2일 오전 문재인 대통령 면담을 요구하며 청와대 춘추관 진입을 시도하고 있다. 2019.5.2     xyz@yna.co.kr▶네이버 홈에서 [] 채널 구독하기▶뭐 하고 놀까? #흥  ▶쇼미더뉴스! 오늘 많이 본 뉴스영상',\n",
       " '【서울=】전신 기자 = 문재인 대통령이 3일 청와대 본관에서 김동찬 주크로아티아대사에 신임장을 수여하고 있다. 2019.05.03.photo1006@.com<저작권자ⓒ 공감언론 통신사. 무단전재-재배포 금지.>',\n",
       " '[ 최경민  기자] [[the300]靑 \"그만큼 화기애애한 분위기\"]【워싱턴(미국)=】박진희 기자 = 문재인 대통령과 부인 김정숙 여사가 지난달 11일 오후(현지시각) 미국 워싱턴 백악관에서 열린 한미 정상회담을 마치고 도널드 트럼프 미국 대통령 내외와 환담하고 있다. 2019.04.12.   pak7130@.com\"김정숙 여사에게도 안부를 전해달라\"8일 청와대에 따르면 전날 늦은 오후 진행된 한미 정상통화 도중에 도널드 트럼프 대통령은 문재인 대통령에게 이같이 말했다.문 대통령과 북한 발사체 발사, 북측에 대한 인도적 식량지원 등 민감한 현안을 논하면서도, 김 여사의 안부를 물은 것이다.김 여사는 트럼프 대통령 뿐만 아니라 그의 가족들과도 꾸준히 접촉해왔다. 지난달 백악관을 방문했을 때는 트럼프 대통령의 부인 멜라니아 여사와 단독 오찬을 가졌다. 한미 퍼스트레이디 간 단독 오찬은 노태우 전 대통령 시절 이후 30년 만이었다.지난해 평창 동계올림픽 때는 트럼프 대통령의 딸 이방카 백악관 보좌관과 스노보드 경기를 함께 관람한 적도 있다. 청와대 관계자는 한미 정상통화 와중에 트럼프 대통령이 김 여사의 안부를 물은 것과 관련해 \"그만큼 통화 분위기가 화기애애했던 것\"이라고 말했다. 한편 트럼프 대통령은 7일 문 대통령과의 통화에서 \"한국이 인도적 차원에서 북한에 식량을 제공하는 것이 매우 시의적절하며 긍정적인 조치가 될 것\"이라고 밝혔다.고민정 청와대 대변인은 \"양 정상은 지난 4일 발사체 발사에도 불구하고 북한이 비핵화를 위한 대화 궤도에서 이탈하지 않도록 하면서, 가능한 조기에 비핵화 협상을 재개하기 위한 방안에 관해 의견을 교환했다\"고 설명했다.최경민  기자 brown@mt.co.kr▶진주 아파트 방화·살인범은 왜?▶조 변호사의 가정상담소  ▶한달 내내 쓰는 마스크 당첨 기회  <저작권자 ⓒ \\'돈이 보이는 리얼타임 뉴스\\' , 무단전재 및 재배포 금지>',\n",
       " '(서울=) 한상균 기자 = 문재인 대통령이 3일 오후 청와대에서 권기창 주우크라이나 대사에게 신임장을 전달하고 있다. 2019.5.3    xyz@yna.co.kr▶네이버 홈에서 [] 채널 구독하기▶뭐 하고 놀까? #흥  ▶쇼미더뉴스! 오늘 많이 본 뉴스영상',\n",
       " '문재인 대통령이 어린이날인 5일 오전 청와대 본관 입구에서 초청된 어린이들을 반갑게 맞이하고 있다. 이날 청와대는 강원도 산불진화 소방관, 군인, 경찰 자녀와 산불 피해 초등학교 학생 및 아동정책 수혜 아동, 독립유공자 후손 등 총 180명의 어린이를 청와대로 초청해 행사를 열었다. (청와대 제공) 2019.5.5/sowon@.kr▶ [ 해피펫 ]  [ KFF포럼 2019 ] ▶ 네이버 메인에서 [] 구독하기![© 코리아(.kr), 무단 전재 및 재배포 금지]',\n",
       " '문재인 대통령이 취임 2주년을 하루 앞둔 9일 청와대 상춘재에서 열린 KBS 특집 대담 프로그램 ‘대통령에게 묻는다’에 출연하고 있다.(청와대 제공=)[ 김성곤 기자] 文대통령, 박근혜 사면? “재판 확정 이전에 사면 말하는 것 어려운 일”(속보)취임 2주년 하루 앞둔 9일 KBS와 특집대담김성곤 (skzero@.co.kr)네이버 홈에서 ‘’ 뉴스 [구독하기▶]꿀잼가득 [영상보기▶] , 청춘뉘우스~ [스냅타임▶]＜ⓒ종합 경제정보 미디어  - 무단전재 & 재배포 금지＞',\n",
       " '[ 김성휘  기자] [[the300]보호자 등 256명 靑 본관 관람하고 유튜브스타들 만나]문재인 대통령과 김정숙 여사는 오는 5일 제97회 어린이날을 맞아 전국 각계각층 어린이와 그 보호자 등 256명을 청와대로 초청, 어린이날 행사를 연다.본관 집무실 관람, 인기 유튜버들과 만남, 어린이뮤지컬 관람 등을 함께한다. 초청 대상으로는 강원 산불 진화에 힘쓴 소방관들의 자녀, 예정했던 식목일 행사를 산불 탓에 하지 못했던 경북 봉화의 초등학생 등 의미있는 \\'작은 영웅\\'들이 포함됐다.【서울=】전신 기자 = 문재인 대통령이 5일 청와대 녹지원에서 열린 2018 어린이날 청와대 초청행사에서 한 아이로부터 풍선을 선물받고 있다. 2018.05.05.   photo1006@.com  <저작권자ⓒ 공감언론 통신사. 무단전재-재배포 금지.>【서울=】전신 기자 = 문재인 대통령 부인 김정숙 여사가 5일 청와대 녹지원에서 열린 2018 어린이날 청와대 초청행사에서 어린이들과 함께 박 터뜨리기를 하고 있다. 2018.05.05.   photo1006@.com  <저작권자ⓒ 공감언론 통신사. 무단전재-재배포 금지.>문 대통령 부부는 ‘대한민국을 이끌어갈 우리들은 미래의 영웅’이란 주제로 예년과 달리 다양한 분야의 어린이들을 청와대로 초청한다고 3일 청와대가 밝혔다. 우선 강원 산불 진화에 애쓴 소방관 군인 경찰관의 자녀 및 강원 산불 피해 초등학교 학생들이다. 문 대통령과 식목일 행사를 함께하기로 하였으나 강원 산불로 행사가 취소됐던 경북 봉화 서벽초등학교 학생들도 온다. 지난 3월 세계 물의 날 행사에 공연자로 참석했다가 문 대통령에게 \"청와대로 초청해주세요\"라고 부탁했던 대구시립 소년소녀어린이합창단도 초대한다.임시정부 및 3.1운동 100주년을 기념해 독립유공자 후손 가정의 어린이를 초청한다. 한부모-미혼모-다문화 가정, 아동수당 수급 다둥이 가정, 국공립 어린이집 및 유치원 재원생, 방과후학교 등 온종일돌봄 이용 아동 등도 초대했다. 문재인 정부의 다양한 아동-가족정책의 직접 대상자들이다.이날 오전 어린이들은 국군 군악대 연주와 함께 청와대로 입장, 본관의 대통령 집무실을 관람한다. 이날 하루 영빈관은 체험형 테마파크로 탈바꿈한다. 이곳에선 캐릭터 인형과 사진찍기, 페이스 페인팅, 팽이시합, 에어시소 등을 즐길 수 있다.이어 \\'어린이 대통령\\'으로 불릴 만큼 인기가 높은 허팝(허재원), 헤이지니(강혜진), 강씨의 친오빠이자 그 자신도 유튜버인 \\'럭키강이\\' 등과 만난다. 문 대통령 부부는 행사 마지막 순서로 어린이들과 함께 뮤지컬 \\'런닝맨 마지막 승자\\'을 관람한다. 행사 종료 후 참석 어린이들은 보호자 등과 함께 미리 준비된 친환경 도시락으로 점심 식사를 하고 영빈관 앞마당에 전시된 경호·의전차량 탑승 체험을 한다. 이들은 청와대 로고가 담긴 학용품 등 선물도 받는다. 문 대통령은 \\'우리들은 미래의 영웅\\'이라는 주제 관련, 4월 강원 산불 진화에 노력했던 소방관, 군인, 경찰들이 최근에 생각나는 영웅이라는 뜻에서 소방관들을 직접 격려할 예정이다. 문 대통령은 2017년 어린이날을 지난 5월10일 취임, 2018년에 이어 청와대 어린이날 행사가 이번이 두 번째다. 김성휘  기자 sunnykim@mt.co.kr▶진주 아파트 방화·살인범은 왜?▶조 변호사의 가정상담소  ▶한달 내내 쓰는 마스크 당첨 기회  <저작권자 ⓒ \\'돈이 보이는 리얼타임 뉴스\\' , 무단전재 및 재배포 금지>',\n",
       " '어버이날 앞두고 부인 김정숙 여사와 함께 센터 들러문재인 대통령. 2019.4.29/(서울=) 조소영 기자 = 문재인 대통령이 어버이날을 하루 앞둔 7일 부인 김정숙 여사와 함께 서울 금천구 치매안심센터를 방문했다. 문 대통령 내외는 이날 센터에서 이용자들에게 제공되는 서비스를 직접 체험해보고 치매어르신, 가족들과 함께 카네이션을 만드는 데에도 함께 했다.문 대통령의 치매안심센터 방문은 이번이 처음이다. 김 여사는 지난해 5월8일 남양주, 올해 1월23일 종로구에 이어 이날이 세 번째 치매안심센터 방문이었다. 문 대통령은 지난 대선 당시 개인과 가정이 떠안았던 치매 부담을 정부가 나눠지겠다는 치매국가책임제를 공약한 바 있다.문 대통령 부부는 먼저 다감각치료실에서 시각과 청각·후각·촉각 등 여러 감각을 깨워 뇌를 활성화시키는 다감각치료 기구를 둘러본 후, 효과가 좋은 치료프로그램을 다수 발굴해 운영해줄 것을 관계자들에게 당부했다.뒤이어 프로그램실로 이동해 치매어르신, 가족들과 함께 종이 카네이션을 함께 만들었다. 종이를 접던 문 대통령은 이같은 활동이 \"치매의 진행을 늦추고 가족과도 함께 시간을 보낼 수 있는 좋은 기회인 듯하다\"고 소감을 밝혔다.이 자리에 함께한 김옥화(79·치매어르신 배우자) 할머니는 \"남편을 돌보느라 우울증에 걸렸었는데 가족교실에 참여하면서 도움을 받았다. 기저귀 같은 물품도 지원받을 수 있어 감사하다\"고 말했다.문 대통령 내외는 이후 완성된 카네이션을 각각 치매어르신께 달아드린 다음, 치매어르신과 가족, 자원봉사자, 치매안심센터 종사자 등과 대화하는 시간을 가졌다. 문 대통령 부부는 이 자리에서 \"국민들과 가장 가까운 지역사회에서 치매로부터 국민을 책임지는 중요한 기관이 치매안심센터\"라며 \"누구나 혜택을 받을 수 있도록 치매안심센터를 잘 운영해달라\"고 당부했다.치매가 아니지만 치매안심센터를 자주 찾는다는 이순복(75) 할머니는 \"센터에서 운영 중인 작업치료, 서예교실, 종이공예교실 등에 참여하고 있다\"며 \"기억력교실이 치매예방에 많은 도움이 되는 것 같다\"고 했다. 이와 함께 지난 4월 최고령으로 요양보호사 자격시험에 합격한 최대식(91) 할아버지는 \"치매를 앓는 아내를 더 잘 보살피기 위한 도전이 이루어진 것 같다\"고 소감을 밝히기도 했다.문 대통령은 센터 관계자들에게 치매예방과 관련된 프로그램에 대해 묻기도 했다. 박지영 팀장은 이에 작업치료와 운동·미술·음악·원예 등을 활용해 뇌활동에 도움이 되도록 운영 중이고 치매어르신을 둔 가족들을 위한 정기 가족모임, 가족카페 등이 특히 호응이 높다고 답했다.문 대통령은 \"치매국가책임제가 시행된지 2년차를 맞아 치매환자와 가족들의 부담을 많이 덜어드릴 수 있는 점을 큰 성과로 꼽고 싶다\"며 \"많은 국민이 치매국가책임제의 혜택을 더 생생하게 체감할 수 있도록 노력하겠다\"고 말했다.cho11757@.kr▶ [ 해피펫 ]  [ KFF포럼 2019 ] ▶ 네이버 메인에서 [] 구독하기![© 코리아(.kr), 무단 전재 및 재배포 금지]']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:10] #test data에서 앞 10개를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['연합뉴스', '노컷뉴스', '연합뉴스', '뉴시스', '머니투데이', '연합뉴스', '뉴스1', '이데일리',\n",
       "       '뉴시스', '연합뉴스'], dtype='<U6')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test_tfidf[:10]) # test data의 앞 10개에 대한 예측내용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['연합뉴스', '노컷뉴스', '연합뉴스', '뉴시스', '머니투데이', '연합뉴스', '뉴스1', '이데일리', '머니투데이', '뉴스1']\n"
     ]
    }
   ],
   "source": [
    "print(y_test[:10]) # test data 앞 10개의 실제 뉴스회사 이름"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 성능을 개선하기 위한 노력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['전국', '장애인', '부모', '연대', '회원', '들', '이', '2일', '오전', '발달장애', '주간', '활동', '서비스', '도입', '을', '촉구', '하며', '청와대', '춘추관', '진입', '을', '시도', '하다', '실패한', '후', '문재인', '대통령', '면담', '요청서', '를', '청와대', '관계자', '에게', '전달', '하고', '있다', '.', '청와대', '사진기', '자단', '▶', '네이버', '메인', '에서', '받아', '보기', '▶', '두고', '두고', '읽는', '뉴스', '▶', '인기', '무료', '만화', '©', '(www.khan.co.kr', '),', '무단', '전', '재', '및', '재', '배포', '금지']\n"
     ]
    }
   ],
   "source": [
    "# morphs()는 명사 외에도 모든 형태소를 포함\n",
    "print(twitter_tag.morphs(X_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score 0.9582470669427191\n",
      "Test score 0.9327817993795243\n",
      "(2898, 23380)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=twitter_tag.morphs, min_df=2) # 명사 대신 모든 형태소를 사용\n",
    "#tfidf = TfidfVectorizer(tokenizer=twit_tokenizer, min_df=3, max_df=0.90, max_features=1000, use_idf=True, sublinear_tf=True)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "print('Train score', clf.score(X_train_tfidf, y_train))\n",
    "print('Test score', clf.score(X_test_tfidf, y_test))\n",
    "print(X_train_tfidf.shape)\n",
    "#명사만 사용한 것에 비해 train score는 상승, test score는 하락"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('전국', 'Noun'), ('장애인', 'Noun'), ('부모', 'Noun'), ('연대', 'Noun'), ('회원', 'Noun'), ('들', 'Suffix'), ('이', 'Josa'), ('2일', 'Number'), ('오전', 'Noun'), ('발달장애', 'Noun'), ('주간', 'Noun'), ('활동', 'Noun'), ('서비스', 'Noun'), ('도입', 'Noun'), ('을', 'Josa'), ('촉구', 'Noun'), ('하다', 'Verb'), ('청와대', 'Noun'), ('춘추관', 'Noun'), ('진입', 'Noun'), ('을', 'Josa'), ('시도', 'Noun'), ('하다', 'Verb'), ('실패하다', 'Adjective'), ('후', 'Noun'), ('문재인', 'Noun'), ('대통령', 'Noun'), ('면담', 'Noun'), ('요청서', 'Noun'), ('를', 'Josa'), ('청와대', 'Noun'), ('관계자', 'Noun'), ('에게', 'Josa'), ('전달', 'Noun'), ('하다', 'Verb'), ('있다', 'Adjective'), ('.', 'Punctuation'), ('청와대', 'Noun'), ('사진기', 'Noun'), ('자단', 'Noun'), ('▶', 'Foreign'), ('네이버', 'Noun'), ('메인', 'Noun'), ('에서', 'Josa'), ('받다', 'Verb'), ('보기', 'Noun'), ('▶', 'Foreign'), ('두다', 'Verb'), ('두다', 'Verb'), ('읽다', 'Verb'), ('뉴스', 'Noun'), ('▶', 'Foreign'), ('인기', 'Noun'), ('무료', 'Noun'), ('만화', 'Noun'), ('©', 'Foreign'), ('(www.khan.co.kr', 'URL'), ('),', 'Punctuation'), ('무단', 'Noun'), ('전', 'Modifier'), ('재', 'Noun'), ('및', 'Noun'), ('재', 'Noun'), ('배포', 'Noun'), ('금지', 'Noun')]\n"
     ]
    }
   ],
   "source": [
    "print(twitter_tag.pos(X_train[1], norm=True, stem=True)) #pos()는 형태소와 품사를 함께 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twit_tokenizer2(text): #전체를 다 사용하는 대신, 명사, 동사, 형용사를 사용\n",
    "    target_tags = ['Noun', 'Verb', 'Adjective']\n",
    "    result = []\n",
    "    for word, tag in twitter_tag.pos(text, norm=True, stem=True):\n",
    "        if tag in target_tags:\n",
    "            result.append(word)\n",
    "#            result.append('/'.join([word, tag]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['전국', '장애인', '부모', '연대', '회원', '오전', '발달장애', '주간', '활동', '서비스', '도입', '촉구', '하다', '청와대', '춘추관', '진입', '시도', '하다', '실패하다', '후', '문재인', '대통령', '면담', '요청서', '청와대', '관계자', '전달', '하다', '있다', '청와대', '사진기', '자단', '네이버', '메인', '받다', '보기', '두다', '두다', '읽다', '뉴스', '인기', '무료', '만화', '무단', '재', '및', '재', '배포', '금지']\n"
     ]
    }
   ],
   "source": [
    "print(twit_tokenizer2(X_train[1])) # 사용 예"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score 0.9406487232574189\n",
      "Test score 0.8738366080661841\n",
      "(2898, 9687)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=twit_tokenizer2, min_df=2) #명사, 동사, 형용사를 이용하여 tfidf 생성\n",
    "#tfidf = TfidfVectorizer(tokenizer=twit_tokenizer, min_df=3, max_df=0.90, max_features=1000, use_idf=True, sublinear_tf=True)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "print('Train score', clf.score(X_train_tfidf, y_train))\n",
    "print('Test score', clf.score(X_test_tfidf, y_test))\n",
    "print(X_train_tfidf.shape)\n",
    "# 현재까지 중에서 test score가 가장 뛰어남"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 형태소를 다 사용하고 품사를 알 수 있도록 하면?\n",
    "def twit_tokenizer3(text):\n",
    "    #target_tags = ['Noun', 'Verb', 'Adjective']\n",
    "    result = []\n",
    "    for word, tag in twitter_tag.pos(text, norm=True, stem=True):\n",
    "        result.append('/'.join([word, tag])) #단어의 품사를 구분할 수 있도록 함\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score 0.9565217391304348\n",
      "Test score 0.9234746639089969\n",
      "(2898, 19268)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=twit_tokenizer3, min_df=2)\n",
    "#tfidf = TfidfVectorizer(tokenizer=twit_tokenizer, min_df=3, max_df=0.90, max_features=1000, use_idf=True, sublinear_tf=True)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "print('Train score', clf.score(X_train_tfidf, y_train))\n",
    "print('Test score', clf.score(X_test_tfidf, y_test))\n",
    "print(X_train_tfidf.shape)\n",
    "#성능이 오히려 떨어지고 품사 표시 없이 전체를 다 사용한 경우에 비해 train은 떨어지고, test는 올라감"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.995\n",
      "Test set score: 0.988\n"
     ]
    }
   ],
   "source": [
    "# train score가 높으므로 ridge를 쓰면 어떨까?\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "ridge_clf = RidgeClassifier(alpha = 1)\n",
    "ridge_clf.fit(X_train_tfidf, y_train)\n",
    "print('Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
    "print('Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))\n",
    "# train score가 올라가는 현상이 벌어짐\n",
    "# test score가 올라갔으나 명사, 형용사, 동사를 쓴 것보다 떨어짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.972\n",
      "Test set score: 0.960\n",
      "Used features count: 151 out of 19268\n"
     ]
    }
   ],
   "source": [
    "#lasso를 쓰면?\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "lasso_clf = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "lasso_clf.fit(X_train_tfidf, y_train)\n",
    "print('Train set score: {:.3f}'.format(lasso_clf.score(X_train_tfidf, y_train)))\n",
    "print('Test set score: {:.3f}'.format(lasso_clf.score(X_test_tfidf, y_test)))\n",
    "print('Used features count: {}'.format(np.sum(lasso_clf.coef_ != 0)), 'out of', X_train_tfidf.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01749844 0.06259259 0.04867669 0.02820975 0.0261339  0.02292455\n",
      " 0.0216244  0.02032561 0.01799395 0.01646622 0.01590068 0.01329175\n",
      " 0.01186406 0.01054471 0.01043772 0.00999851 0.00980958 0.00949685\n",
      " 0.00899328 0.00839679 0.00814633 0.00797232 0.00764513 0.007358\n",
      " 0.00710842 0.00696733 0.00664081 0.00632563 0.00624871 0.00590439\n",
      " 0.00587019 0.00545757 0.00539159 0.00530238 0.00501105 0.00480495\n",
      " 0.00471938 0.00453381 0.004455   0.00435139 0.00422777 0.0040918\n",
      " 0.00396747 0.0039218  0.00377193 0.00373484 0.00368934 0.00358876\n",
      " 0.00354618 0.00346198 0.00345037 0.00334575 0.00331011 0.00322603\n",
      " 0.00320981 0.00315917 0.00310058 0.00306519 0.00301535 0.00295869\n",
      " 0.00294814 0.0028852  0.00286418 0.00278192 0.00273721 0.00268792\n",
      " 0.0026802  0.00262345 0.00255143 0.00251287 0.00248258 0.00245528\n",
      " 0.00241811 0.00236538 0.00234642 0.0023207  0.00225045 0.00224059\n",
      " 0.00218883 0.00217195 0.00213246 0.00211904 0.00208108 0.0020428\n",
      " 0.0020308  0.00199983 0.00199294 0.00194749 0.00193893 0.00189195\n",
      " 0.00186534 0.00185383 0.00182308 0.00181991 0.00175092 0.00174402\n",
      " 0.00173111 0.00171248 0.00169992 0.00166746 0.00165056 0.0016405\n",
      " 0.00162052 0.00160287 0.001589   0.00155671 0.00153776 0.00150653\n",
      " 0.00150206 0.00148187 0.00147436 0.00144391 0.00144194 0.00143207\n",
      " 0.00141608 0.00139608 0.00138826 0.00138106 0.00136436 0.00135968\n",
      " 0.00133741 0.00133086 0.00131275 0.00130268 0.00129953 0.00129282\n",
      " 0.00127473 0.00124901 0.00124078 0.00122934 0.00122579 0.00120141\n",
      " 0.00119911 0.00118305 0.0011613  0.0011486  0.00114076 0.00113672\n",
      " 0.00112091 0.00111464 0.00110364 0.00109579 0.00108465 0.00108417\n",
      " 0.00107835 0.0010677  0.00104695 0.00104078 0.00103282 0.00102072]\n",
      "0.734539522922357\n",
      "[21.70349082 12.6011149  10.98221853  8.34641881  8.02257687  7.52177762\n",
      "  7.30267511  7.07495201  6.65774683  6.37655714  6.25720339  5.75834527\n",
      "  5.40533163  5.0963774   5.07024308  4.96241038  4.91631348  4.84240346\n",
      "  4.70644596  4.54891872  4.47991633  4.4307462   4.34195021  4.25947174\n",
      "  4.18391965  4.14323393  4.04382626  3.94671961  3.92257686  3.81292232\n",
      "  3.80255101  3.66604289  3.64358344  3.61341041  3.51325772  3.43972891\n",
      "  3.40890858  3.34163169  3.31416779  3.2737017   3.22725618  3.17495137\n",
      "  3.12555522  3.10855693  3.04766422  3.03253845  3.01437604  2.97267727\n",
      "  2.95555758  2.91966894  2.91521488  2.87063087  2.85608653  2.81883381\n",
      "  2.8113236   2.78916204  2.76307367  2.74728628  2.72499042  2.69912295\n",
      "  2.69444711  2.66617038  2.65572293  2.6179342   2.59613321  2.57270685\n",
      "  2.56904768  2.54165019  2.50713102  2.48764815  2.47242229  2.45903043\n",
      "  2.44019134  2.41340464  2.4037098   2.39045195  2.35415149  2.3489141\n",
      "  2.32154577  2.31261146  2.29156391  2.28423819  2.26381174  2.24286862\n",
      "  2.23617457  2.21914595  2.21526549  2.18989469  2.18502247  2.15837124\n",
      "  2.14321045  2.13651051  2.11873694  2.11694126  2.0764857   2.07226666\n",
      "  2.06464626  2.05391197  2.04591493  2.02628478  2.01597766  2.00993357\n",
      "  1.99758988  1.98694715  1.97804898  1.95795468  1.94611788  1.92601649\n",
      "  1.92326407  1.91018479  1.90545802  1.8857183   1.88431037  1.87803507\n",
      "  1.86731747  1.8540785   1.84886946  1.84406903  1.83290032  1.82974994\n",
      "  1.81479791  1.81048768  1.79788476  1.79099905  1.78892542  1.78424285\n",
      "  1.77167768  1.75374043  1.74796197  1.73982801  1.73733377  1.72004049\n",
      "  1.7183019   1.70677046  1.69099737  1.68172414  1.67605103  1.67309082\n",
      "  1.66132823  1.65667457  1.64849517  1.64263645  1.63426058  1.63392288\n",
      "  1.62950301  1.62145117  1.60558713  1.60093199  1.5947133   1.58535011]\n",
      "(150, 19268)\n"
     ]
    }
   ],
   "source": [
    "#lsa를 쓰면?\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=150, n_iter=7, random_state=42) #압축할 component의 수 지정\n",
    "svd.fit(X_train_tfidf)  \n",
    "print(svd.explained_variance_ratio_)  #계산된 각 component가 설명하는 분산의 비율\n",
    "print(svd.explained_variance_ratio_.sum())  #선택된 component들이 설명하는 분산의 합 -> 선택한 component의 수에 따라 달라짐\n",
    "print(svd.singular_values_) \n",
    "print(svd.components_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.929\n",
      "Test set score: 0.904\n"
     ]
    }
   ],
   "source": [
    "X_train_svd = svd.transform(X_train_tfidf) #선택된 component를 이용하여 19000개의 feature로부터 feature extract (dimension reduce)\n",
    "X_test_svd = svd.transform(X_test_tfidf)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "SVD_clf = LogisticRegression()\n",
    "SVD_clf.fit(X_train_svd, y_train)\n",
    "print('Train set score: {:.3f}'.format(SVD_clf.score(X_train_svd, y_train)))\n",
    "print('Test set score: {:.3f}'.format(SVD_clf.score(X_test_svd, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 높은 정확도의 이유.\n",
    "\n",
    "정확도가 높게 나온 이유는 기사 내용에 뉴스 사이트, 기자의 이름 등의 패턴으로 학습이 되었기 때문이라 생각됨.\n",
    "기사에 있는 뉴스 회사 이름은 전처리 과정에서 삭제하였으나, '기자명@chosun' 등 기자의 이메일이나 www.경향신문.com 과 같은 주소명이 기사내용에 남아 있었음.\n",
    "추후 전처리를 통해 제대로된 분류를 해볼 계획임."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
